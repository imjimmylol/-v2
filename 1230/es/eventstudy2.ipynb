{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import eventstudy as es\n",
    "from tqdm import tqdm\n",
    "import itertools   \n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "cn = pd.read_csv(\"../../1223/data/concentration/concentration/2020_20230814.csv\", index_col=False).dropna()\n",
    "q = pd.read_csv(\"../../1223/data/concentration/quote/2020_20230814.csv\", index_col=False).dropna()\n",
    "rf = pd.read_csv(\"../../1223/data/concentration/rf/rf.csv\").dropna().rename(columns={'日期':'date'})\n",
    "df = pd.merge(q, cn, on=['日期', '股號'], how='left')\n",
    "df = df.groupby('股號').apply(lambda x: x.sort_values('日期')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# get marketret data\n",
    "stock_code = \"^TWII\"\n",
    "\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2023-12-31\" \n",
    "\n",
    "twii_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "twii_data['date'] =  pd.to_datetime(twii_data.index)\n",
    "twii_data['ret'] = twii_data['Adj Close'].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutate col\n",
    "df = pd.merge(q, cn, on=['日期', '股號'], how='left').reset_index(drop=True)\n",
    "# df = df.groupby('股號').apply(lambda x: x.sort_values('日期')).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 量起\n",
    "df['成交量_1'] = df.groupby('股號', as_index=False)['成交量'].shift(-1)\n",
    "\n",
    "def divide_two_cols(df_sub):\n",
    "    df_sub['volume_delta_1'] = df_sub['成交量_1'] / df_sub['成交量']\n",
    "    return df_sub\n",
    "\n",
    "df = df.groupby('股號', as_index=False).apply(divide_two_cols)\n",
    "\n",
    "\n",
    "# 價揚\n",
    "# shift 1 假設是成交量出現異常後的下一根進場\n",
    "df['ret'] = df.groupby('股號')['收盤價'].pct_change()\n",
    "df['ret_2'] = df.groupby('股號')['ret'].shift(-1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ret_df(df):\n",
    "\n",
    "    uq_id = df['股號'].unique()\n",
    "    res_by_ticker = []\n",
    "    res = None\n",
    "\n",
    "    for ticker_id in tqdm(uq_id[:len(uq_id)]):\n",
    "        ticker_df = df[df['股號']==ticker_id].reset_index(drop=True)\n",
    "\n",
    "        date = ticker_df['日期'].tolist()\n",
    "        ret = ticker_df['ret'].tolist()\n",
    "\n",
    "        ticker_ret_df = pd.DataFrame(list(zip(date, ret)),\n",
    "               columns =['date', f'{ticker_id}'])\n",
    "        \n",
    "        res_by_ticker.append(ticker_ret_df)\n",
    "    for i in tqdm(range(len(res_by_ticker))):\n",
    "        if i == 0:\n",
    "            res = res_by_ticker[i]\n",
    "\n",
    "        else:\n",
    "            res = pd.merge(res, res_by_ticker[i], how='left', on='date')\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [01:04<00:00, 20.96it/s]\n",
      "100%|██████████| 1350/1350 [00:05<00:00, 262.97it/s]\n"
     ]
    }
   ],
   "source": [
    "return_df = create_ret_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf[\"date\"] = pd.to_datetime(rf['date'])\n",
    "return_df[\"date\"] =  pd.to_datetime(return_df[\"date\"])\n",
    "\n",
    "main_df_4analysis = pd.merge(return_df, rf, how='left', on='date')\n",
    "main_df_4analysis = pd.merge(main_df_4analysis, twii_data, how='left', on='date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:26<00:00, 51.08it/s]\n"
     ]
    }
   ],
   "source": [
    "uq_id = df['股號'].unique()\n",
    "\n",
    "for tick in tqdm(uq_id[:]):\n",
    "    \n",
    "    # make a copy\n",
    "    copy = main_df_4analysis.copy()\n",
    "    \n",
    "    # ret df     \n",
    "    copy = copy.dropna(subset=[str(tick), 'ret'])\n",
    "    returns_df =copy.iloc[:,[main_df_4analysis.columns.get_loc(c) for c in ['date', f'{tick}']]] \n",
    "    \n",
    "    # fama df\n",
    "    famadf = copy.iloc[:,[copy.columns.get_loc(c) for c in ['date', '收市', 'ret']]].rename(columns={'收市':'RF', 'ret':'MktRt'})\n",
    "    famadf['Mkt-RF'] = famadf['MktRt'] - famadf['RF']\n",
    "    famadf['SMB'] = 0\n",
    "    famadf['HML'] = 0\n",
    "    \n",
    "    # merge \n",
    "    tmp = pd.merge(returns_df, famadf, how='left', on='date')\n",
    "    tmp.sort_values(by='date', inplace = True)\n",
    "    tmp = tmp.dropna()\n",
    "    \n",
    "    # sub df\n",
    "    tmp.iloc[:,[tmp.columns.get_loc(c) for c in ['date', f'{tick}']]].to_csv(f'../df/returns_{tick}.csv')\n",
    "    tmp.iloc[:,[tmp.columns.get_loc(c) for c in ['date', 'RF', 'MktRt', 'Mkt-RF', 'SMB', 'HML']]].to_csv(f'../df/fama_{tick}.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [25:05<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "uq_id = df['股號'].unique()\n",
    "final_res = pd.DataFrame(columns=['AR', 'Std. E. AR', 'CAR', 'Std. E. CAR', 'T-stat', 'P-value',\n",
    "       'evnet_window', 'EventDate', 'symbol'])\n",
    "err = []\n",
    "\n",
    "for tick in tqdm(uq_id[:]):\n",
    "    \n",
    "\n",
    "    es.Single.import_returns(path=f'../df/returns_{tick}.csv', date_format = '%Y-%m-%d')\n",
    "    es.Single.import_FamaFrench(path=f'../df/fama_{tick}.csv', date_format = '%Y-%m-%d')\n",
    "\n",
    "    # df tick\n",
    "    df_tick = df[df['股號']==tick].reset_index(drop=True)\n",
    "\n",
    "    # get event date\n",
    "    vol_increase_id = df_tick[(df_tick['成交量']>500)&(df_tick['volume_delta_1']>2)].index\n",
    "    event_date = df_tick['日期'][vol_increase_id].to_list()\n",
    "    # print(tick, event_date)\n",
    "\n",
    "    for ed in event_date:\n",
    "        try:\n",
    "            \n",
    "            event = es.Single.FamaFrench_3factor(\n",
    "                security_ticker = str(tick),\n",
    "                event_date = np.datetime64(str(ed)),\n",
    "                event_window = (0,+10), \n",
    "                estimation_size = 30, # 注意這個\n",
    "                buffer_size = 30,\n",
    "                keep_model=False\n",
    "            )\n",
    "            tick_res = event.results(decimals=[3,5,3,5,2,2])\n",
    "            tick_res['evnet_window'] = tick_res.index\n",
    "            tick_res['EventDate'] =  np.datetime64(ed)\n",
    "            tick_res['symbol'] = tick\n",
    "            tick_res = tick_res.reset_index(drop=True)\n",
    "            # final_res = final_res.append(tick_res, ignore_index=True)\n",
    "            final_res = pd.concat([final_res, tick_res], ignore_index=True)\n",
    "        except:\n",
    "            err.append([tick, ed])\n",
    "            continue\n",
    "\n",
    "    # print(final_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = final_res.rename(columns={'P-value':'p', 'T-stat':'t'})\n",
    "final_res['evnet_window'] = final_res['evnet_window'].astype(str).astype(int)\n",
    "final_res['symbol'] = final_res['symbol'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_res.groupby(['symbol', 'EventDate']).filter(lambda x: ((x.p<= 0.05) & (x.evnet_window > 0)).all())\n",
    "res_analysis = final_res.assign(\n",
    "    \n",
    "    # the second position is where to sum\n",
    "    negative_significant_after_event = np.where((final_res['evnet_window']>0) & (final_res['t']<0), final_res['p']<=0.05, 0),\n",
    "    positive_significant_after_event = np.where((final_res['evnet_window']>0) & (final_res['t']>0), final_res['p']<=0.05, 0),\n",
    "    \n",
    "    \n",
    ").groupby(['EventDate', 'symbol'], as_index=False).agg({'negative_significant_after_event':sum, 'positive_significant_after_event':sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 10\n",
    "\n",
    "## 1. There are more then N volumne increase singal \n",
    "N_SIGNAL = 10\n",
    "\n",
    "## 2. window significant percentage\n",
    "POSITIVE_SIG_PERCENT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_analysis['pos_sig_per'] = res_analysis['positive_significant_after_event']/WINDOW_SIZE\n",
    "res_analysis['neg_sig_per'] = res_analysis['negative_significant_after_event']/WINDOW_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventDate</th>\n",
       "      <th>symbol</th>\n",
       "      <th>negative_significant_after_event</th>\n",
       "      <th>positive_significant_after_event</th>\n",
       "      <th>pos_sig_per</th>\n",
       "      <th>neg_sig_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>4102</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>2392</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>3013</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>3163</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>6245</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82651</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>3234</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82663</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>3706</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82669</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>4908</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82677</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>5388</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82694</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>6412</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11060 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EventDate symbol  negative_significant_after_event  \\\n",
       "48    2020-04-10   4102                                 0   \n",
       "298   2020-04-14   2392                                 0   \n",
       "341   2020-04-14   3013                                 0   \n",
       "360   2020-04-14   3163                                 0   \n",
       "420   2020-04-14   6245                                 0   \n",
       "...          ...    ...                               ...   \n",
       "82651 2023-07-27   3234                                 0   \n",
       "82663 2023-07-27   3706                                 0   \n",
       "82669 2023-07-27   4908                                 0   \n",
       "82677 2023-07-27   5388                                 0   \n",
       "82694 2023-07-27   6412                                 0   \n",
       "\n",
       "       positive_significant_after_event  pos_sig_per  neg_sig_per  \n",
       "48                                    9          0.9          0.0  \n",
       "298                                   9          0.9          0.0  \n",
       "341                                  10          1.0          0.0  \n",
       "360                                  10          1.0          0.0  \n",
       "420                                   9          0.9          0.0  \n",
       "...                                 ...          ...          ...  \n",
       "82651                                10          1.0          0.0  \n",
       "82663                                10          1.0          0.0  \n",
       "82669                                10          1.0          0.0  \n",
       "82677                                10          1.0          0.0  \n",
       "82694                                 9          0.9          0.0  \n",
       "\n",
       "[11060 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_analysis[res_analysis['pos_sig_per']>POSITIVE_SIG_PERCENT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
