{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from utils import XD\n",
    "from scipy.stats import wilcoxon\n",
    "import pymannkendall as mk\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "cn = pd.read_csv(\"../1223/data/concentration/concentration/2020_20230814.csv\").dropna()\n",
    "q = pd.read_csv(\"../1223/data/concentration/quote/2020_20230814.csv\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## config\n",
    "\n",
    "# window size\n",
    "N_P = 10 \n",
    "\n",
    "# return volume\n",
    "VOL_TRES = 1000\n",
    "\n",
    "# Critical\n",
    "CRITICAL = 0.05\n",
    "\n",
    "# Volume\n",
    "VOLUME_MULTIPLIER = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "df = pd.merge(q, cn, on=['日期', '股號'], how='left')\n",
    "df = df.groupby('股號').apply(lambda x: x.sort_values('日期')).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 量起\n",
    "df['成交量_1'] = df.groupby('股號')['成交量'].shift(1).dropna()\n",
    "\n",
    "def divide_two_cols(df_sub):\n",
    "    df_sub['volume_delta_1'] = df_sub['成交量_1'] / df_sub['成交量']\n",
    "    return df_sub\n",
    "\n",
    "df = df.groupby('股號', as_index=False).apply(divide_two_cols)\n",
    "\n",
    "\n",
    "# 價揚\n",
    "df['ret'] = df.groupby('股號', as_index=False)['收盤價'].pct_change()\n",
    "df['ret_1'] = df.groupby('股號', as_index=False)['ret'].shift(-1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [02:05<00:00, 10.74it/s]\n"
     ]
    }
   ],
   "source": [
    "g_df = df.groupby('股號')\n",
    "\n",
    "stock_uq_id = df['股號'].unique()\n",
    "\n",
    "res_d = {}\n",
    "bug_li = []\n",
    "\n",
    "for id in tqdm(stock_uq_id[:]):\n",
    "    # print(id)\n",
    "\n",
    "    # group by\n",
    "    tmp = g_df.get_group(id)\n",
    "    \n",
    "    # process \n",
    "    vol_increase_id = tmp[(tmp['成交量']>VOL_TRES)&(tmp['volume_delta_1']>VOLUME_MULTIPLIER)].index\n",
    "    tmp['indicator'] = tmp.index.isin(vol_increase_id).astype(int)\n",
    "    tmp['abnormal'] = (tmp['indicator'].shift(1) == 0) & (tmp['indicator'] == 1)\n",
    "    tmp = tmp.dropna()\n",
    "\n",
    "    try:\n",
    "        # calculate cumulative event related return \n",
    "        c, cp = XD.get_indcum(col_ret = tmp['ret_1'], col_abnormal=tmp['abnormal'], num_period=N_P)\n",
    "        tmp[f'cumret_{N_P}'] = c\n",
    "\n",
    "        # test\n",
    "        cp = list(k for k,_ in itertools.groupby(cp))\n",
    "\n",
    "        result_wilcoxon = []\n",
    "        result_trend = []\n",
    "\n",
    "        for i, l in enumerate(cp):\n",
    "\n",
    "            if len(l)>1:\n",
    "                if sum(l) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "\n",
    "                    _, p_value_wilcoxon = wilcoxon(l)\n",
    "                    trend, h, p, z, Tau, s, var_s, slope, intercept =  mk.original_test(l)\n",
    "                    result_wilcoxon.append(p_value_wilcoxon)\n",
    "                    result_trend.append(trend)\n",
    "\n",
    "        res_d[id] = [np.array(result_wilcoxon), np.array(result_trend), len(result_wilcoxon)]\n",
    "        res_d[id].insert(4,tmp['日期'][vol_increase_id])\n",
    "\n",
    "    except UnboundLocalError:\n",
    "        bug_li.append(id)\n",
    "        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:00<00:00, 150409.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(res_d.items()):\n",
    "\n",
    "    # significant signed test\n",
    "    wk_significant_count = len(np.where(res_d[key][0] < CRITICAL)[0].tolist())  \n",
    "    trend_significant_count = len(np.where(res_d[key][1] != 'no trend')[0].tolist())  \n",
    "\n",
    "    # significant percentile\n",
    "    if res_d[key][2]!=0:\n",
    "        wk_significant_perc = wk_significant_count/res_d[key][2]\n",
    "        trend_significant_perc = trend_significant_count/res_d[key][2]\n",
    "\n",
    "        tmp = [wk_significant_count, wk_significant_perc, trend_significant_count, trend_significant_perc]\n",
    "        res_d[key].append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter condition\n",
    "\n",
    "## 1. There are more then N volumne increase singal \n",
    "N_SIGNAL = 10\n",
    "\n",
    "## 2. MK test significant percentage\n",
    "MK_TEST_SIGNIFICANT_PERCENT = 0.7\n",
    "\n",
    "## 3. trend test significant percentage\n",
    "TREND_TEST_SIGNIFICANT_PERCENT = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:00<00:00, 896832.48it/s]\n"
     ]
    }
   ],
   "source": [
    "final_res = {}\n",
    "for key, value in tqdm(res_d.items()):\n",
    "\n",
    "    try:\n",
    "    \n",
    "        if res_d[key][2]!=0:\n",
    "            condi1 = res_d[key][2] > N_SIGNAL\n",
    "            condi2 = res_d[key][4][1] > MK_TEST_SIGNIFICANT_PERCENT\n",
    "            condi3 =  res_d[key][4][3] > TREND_TEST_SIGNIFICANT_PERCENT\n",
    "\n",
    "            if condi1 and condi2 and condi3:\n",
    "                final_res[key] = {'num_sig':res_d[key][2], 'mk_sig_perc':res_d[key][4][1], 'trend_sig_perc':res_d[key][4][3],\n",
    "                                  'Date':res_d[key][3]}\n",
    "\n",
    "    except IndexError:\n",
    "       pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = []\n",
    "date = []\n",
    "for i in final_res.keys():\n",
    "    date.extend(final_res[i]['Date'].values.tolist())\n",
    "    ticker.extend([i for j in range(len(final_res[i]['Date'].values.tolist()))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(list(zip(ticker, date)), columns =['ticker', 'date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(f\"./res/wd{N_P}_vol{VOL_TRES}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
